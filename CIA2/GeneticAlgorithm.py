# -*- coding: utf-8 -*-
"""GeneticAlgorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yqDphWEvkiZgf7_fQuSE1aiTAK36wpSr

##  **Design and Analysis of Algorithms - CIA 2**

### **Question**: 
Design a neural network (the choice of implementation model can be pytorch, tensorflow or the whitebox model) for the data set shared in the ML lab assignment for neural networks. 

* Develop individual code base using following algorithms for weight optimization:
1.	Genetic Algorithm
2.	Cultural Algorithm
3.	Particle Swarm Optimization
4.	Ant Colony Optimization
* 
Data to be uploaded to github
1.	Note on the comparison of performance for the four methods. 
2.	The codebase for all four methods 
3.	The research papers that you have referred to.

### Dependencies and Dataset
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import random

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Accuracy
from tensorflow.keras.utils import to_categorical

from sklearn import metrics
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler

import os
import torch
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
from torchvision import datasets, transforms

data = pd.read_csv(r"/content/drive/MyDrive/Colab Notebooks/Bank_Personal_Loan_Modelling.csv")

"""Columns of the dataset : 
* ID: Customer ID
* Age: Customer Age
* Experience: Amount of work experience in years
* Income: Amount of annual income (in thousands)
* Zipcode: Zipcode of where customer lives
* Family: Number of family members
* CCAvg: Average monthly credit card spendings
* Education: Education level (1: Bachelor, 2: Master, 3: Advanced Degree)
* Mortgage: Mortgage of house (in thousands)
* Securities Account: Boolean of whether customer has a securities account
* CD Account: Boolean of whether customer has Certificate of Deposit account
* Online: Boolean of whether customer uses online banking
* CreditCard: Does the customer use credit card issued by the bank?
* Personal Loan: This is the target variable (Binary Classification Problem)
"""

# We can drop the column Customer ID as they do not help us in the prediction.
df = data.drop(columns=["ID"],axis=1)
df

"""## Exploratory Data Analysis"""

df.info()

df.describe().transpose()

df.isna().any()

# Percentage of customers having credit cards

CC_percent=(len(df[df['CreditCard']==1])/len(df))*100

print('The percentage of customers having credit cards is', CC_percent, '%')

#Number of customers who accepted a loan
accepted_customers= df[df['Personal Loan']==1]

# Percentage of customers who accepted a load
accepted_percent=(len(accepted_customers)/len(df))*100

print('The percentage of customers who accepted a loan', accepted_percent, '%')

"""## Data Visualization"""

df['Education'].value_counts()

# Visualize the Personal loan feature
plt.figure(figsize=(5,5))
sns.countplot(data=df, x="Personal Loan")

# Visualize the education feature
plt.figure(figsize=(5,5))
sns.countplot(data=df, x="Education")

# Visualize the age feature
plt.figure(figsize=(20,10))
sns.countplot(data=df, x="Age")

# Visualize credit card availability

plt.figure(figsize=(10,7))
sns.countplot(data=df, x="CreditCard")

# Visualize income data

sns.distplot(df['Income'])

personal_loans = df[df['Personal Loan'] == 1].copy()
no_personal_loans=df[df['Personal Loan']==0]
plt.figure(figsize=(15,8))
sns.distplot(personal_loans["Income"], label='Approved')
sns.distplot(no_personal_loans["Income"], label='Not Approved')
plt.legend()
plt.show()

"""## Train Test Split"""

df.shape

x = df.iloc[:,:-1].values
y = df.iloc[:,-1].values

x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.25, random_state=69)

sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""# **# PyTorch Neural Network**"""

batch_size = 64

train_x = torch.from_numpy(x_train).to(torch.float32)
train_y = torch.from_numpy(y_train).to(torch.float32)

test_x = torch.from_numpy(x_test).to(torch.float32)
test_y = torch.from_numpy(y_test).to(torch.float32)

class Data(Dataset):
    def __init__(self, x, y):
        self.x = torch.from_numpy(x.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.x.shape[0]
       
    def __getitem__(self, index):
        return self.x[index], self.y[index]
   
    def __len__(self):
        return self.len

train_x.shape, train_y.shape

train_data = TensorDataset(train_x,train_y)
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)

test_data = TensorDataset(test_x,test_y)
test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)

"""# **# Building Model**"""

class NeuralNetwork(torch.nn.Module):
    
    def __init__(self):
        super(NeuralNetwork,self).__init__()
        
        self.layer1 = torch.nn.Linear(12,16)
        self.layer2 = torch.nn.Linear(16,8)
        self.layer3 = torch.nn.Linear(8,1)
        self.sigmoid = torch.nn.Sigmoid()
        self.relu = torch.nn.ReLU()
        
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        x = self.relu(x)
        x = self.layer3(x)
        x = self.sigmoid(x)
        return x

neural_network = NeuralNetwork()

"""# **# Weight Optimization using Genetic Algorithm**"""

def fitness_function(model):
  y_pred = model(train_x)
  y_pred = torch.where(y_pred>=0.5,1,0).flatten()
  accuracy = (y_pred == train_y).sum().float().item() / len(train_dataloader.dataset)
  return round(accuracy, 4)

def mutation(child,matrix_size):
  # Child 1 Mutation
  random_start = random.randrange(0,matrix_size//2)
  random_end = random.randrange(random_start,matrix_size)
  child_mutate = child.copy()
  child_mutate[random_start:random_end] = child_mutate[random_start:random_end][::-1]

  return child_mutate

def crossover(parent1,parent2):
    # Shape of the weights and biases
    shape = [i.numpy().shape for i in parent1.parameters()]
    size = [i[0]*i[1] if len(i) == 2 else i[0] for i in shape]
    
    # Flattening the parameters for cross over
    params1 = np.concatenate([i.numpy().flatten() for i in parent1.parameters()])
    params2 = np.concatenate([i.numpy().flatten() for i in parent2.parameters()])
    
    # Crossover
    crossover_point = random.randrange(np.floor_divide(len(params1), 2) - 10, np.floor_divide(len(params1), 2) + 10)
    
    child_1 = np.concatenate([params1[:crossover_point], params2[crossover_point:]])
    child_2 = np.concatenate([params2[:crossover_point], params1[crossover_point:]])
    
    #Mutation of Child
    child_1_mutate = mutation(child_1,len(params1))
    child_2_mutate = mutation(child_2,len(params2))
    
    # Converting the array to parameters
    children = [child_1, child_2, child_1_mutate, child_2_mutate]
    output = list()
    
    for child in children:
        param = []
        curr_index = 0
        for i in range(len(size)):
            subset = child[curr_index : curr_index + size[i]]
            array = subset.reshape(shape[i])
            curr_index += size[i]
            param.append(array)
        param = np.array(param, dtype="object")
        output.append(param)
    
    output = np.array(output, dtype="object")
    return output

# Training 
torch.manual_seed(420)
torch.set_grad_enabled(False)
population_size = 1000

def train(generations):
  population  = np.array([NeuralNetwork() for i in range(population_size)])
  best = None

  for i in range(generations):
    population = sorted(population, key=lambda x: fitness_function(x))
    best = population[-1]
    if(i%10)==0:
      print(f"Generation {i} : {fitness_function(population[-1])}")

    parents = population[-4:]
    parent_1, parent_2 = population[:2]

    outputs = [crossover(parents[i], parents[i+2]) for i in range(2)]
    output = np.concatenate(outputs)

    new_population = np.array([NeuralNetwork() for i in range(len(output))])
    for i, model in enumerate(new_population,0):
      for j, param in enumerate(model.parameters(),0):
        param.data = (torch.tensor(output[i][j]))

    new_population = np.concatenate([new_population, [parent_1, parent_2]])
    population = new_population.copy()
  
  return best

best_model = train(100)

"""# **Classification Report**"""

y_pred = best_model(test_x)
y_pred = torch.where(y_pred>=0.5, 1, 0).flatten()
genetic = classification_report(y_pred,test_y)
print(genetic)