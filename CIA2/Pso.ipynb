{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10kZXAr6ARU1RlZWALnR9r-HVv7GOnVUZ",
      "authorship_tag": "ABX9TyML6DB4x4ehm/0q//Gsc6ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SG-Akshay10/Dynamic_Programming/blob/main/PSO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Particle Swarm Optimization**"
      ],
      "metadata": {
        "id": "0EwxJuQjNEEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question**: \n",
        "Design a neural network (the choice of implementation model can be pytorch, tensorflow or the whitebox model) for the data set shared in the ML lab assignment for neural networks. \n",
        "\n",
        "* Develop individual code base using following algorithms for weight optimization:\n",
        "1.\tGenetic Algorithm\n",
        "2.\tCultural Algorithm\n",
        "3.\tParticle Swarm Optimization\n",
        "4.\tAnt Colony Optimization\n",
        "* \n",
        "Data to be uploaded to github\n",
        "1.\tNote on the comparison of performance for the four methods. \n",
        "2.\tThe codebase for all four methods \n",
        "3.\tThe research papers that you have referred to.\n",
        "\n"
      ],
      "metadata": {
        "id": "GMwDpLfQuAXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies and Dataset"
      ],
      "metadata": {
        "id": "Az9-oaE7uKQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MYKk01BDtVvM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "dEtH4eNutoEv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "fhHuBB7Zty-S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "eLBhk4fct00H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/Bank_Personal_Loan_Modelling.csv\")"
      ],
      "metadata": {
        "id": "4gqo26yuueCh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns of the dataset : \n",
        "* ID: Customer ID\n",
        "* Age: Customer Age\n",
        "* Experience: Amount of work experience in years\n",
        "* Income: Amount of annual income (in thousands)\n",
        "* Zipcode: Zipcode of where customer lives\n",
        "* Family: Number of family members\n",
        "* CCAvg: Average monthly credit card spendings\n",
        "* Education: Education level (1: Bachelor, 2: Master, 3: Advanced Degree)\n",
        "* Mortgage: Mortgage of house (in thousands)\n",
        "* Securities Account: Boolean of whether customer has a securities account\n",
        "* CD Account: Boolean of whether customer has Certificate of Deposit account\n",
        "* Online: Boolean of whether customer uses online banking\n",
        "* CreditCard: Does the customer use credit card issued by the bank?\n",
        "* Personal Loan: This is the target variable (Binary Classification Problem)"
      ],
      "metadata": {
        "id": "VAiH-H4uuuNm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ee0b800"
      },
      "source": [
        "#### Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6aa8d55a"
      },
      "outputs": [],
      "source": [
        "# Deleting Columns which are not necessary\n",
        "df.drop([\"ID\"],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "HgeEuEIqwJzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH88BNkqv6zi",
        "outputId": "a94a8b32-5c10-4ba7-da81-41e6b03b09a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "p8Ju-6TEwNe9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.2, random_state=69)"
      ],
      "metadata": {
        "id": "OJhxXdIuwORT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "xveATpblwKF1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmDMaa12wSzD",
        "outputId": "19ea6b5e-1a85-4342-8949-57e2338c2edb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4000, 12), (1000, 12), (4000,), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c277b86d"
      },
      "source": [
        "# PyTorch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d1f1c3f1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5dd4e554"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "53b5e253"
      },
      "outputs": [],
      "source": [
        "train_x = torch.from_numpy(x_train).to(torch.float32)\n",
        "train_y = torch.from_numpy(y_train).to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a816e476",
        "outputId": "53ba51cb-7760-4466-fe33-1c2461d13ea4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4000, 12]), torch.Size([4000]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_x.shape, train_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "83535d93"
      },
      "outputs": [],
      "source": [
        "data = TensorDataset(train_x,train_y)\n",
        "data = DataLoader(data,batch_size=BATCH_SIZE,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f359adb"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d4d0b641"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        \n",
        "        self.layer1 = torch.nn.Linear(12,16)\n",
        "        self.layer2 = torch.nn.Linear(16,1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee75431f"
      },
      "source": [
        "# Weight Optimization using Particle Swarm Optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pyswarms"
      ],
      "metadata": {
        "id": "snAlhdYock-h"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "torch.set_grad_enabled(False)\n",
        "param = np.concatenate([i.numpy().flatten() for i in model.parameters()])\n",
        "shape = [i.numpy().shape for i in model.parameters()]\n",
        "size = [i[0]*i[1] if len(i) == 2 else i[0] for i in shape]\n",
        "\n",
        "print(\"Dim : \", len(param))\n",
        "print(\"Layers Shape : \", shape)\n",
        "print(\"Layers Size : \", size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ_d-fTDhsGF",
        "outputId": "051942cb-bbb3-48eb-b1e6-21b1edab5896"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dim :  225\n",
            "Layers Shape :  [(16, 12), (16,), (1, 16), (1,)]\n",
            "Layers Size :  [192, 16, 16, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_function(particle, model, train_x, train_y,shape = shape,size=size):\n",
        "    # Reshape the vector to weights and biases dimension\n",
        "    accuracy = []\n",
        "    output = []\n",
        "\n",
        "    for par in particle:\n",
        "      param = list()\n",
        "      cum_sum = 0\n",
        "      for i in range(len(size)):\n",
        "          array = particle[cum_sum : cum_sum + size[i]]\n",
        "          array = array.reshape(shape[i])\n",
        "          cum_sum += size[i]\n",
        "          param.append(array)\n",
        "      param = np.array(param, dtype=\"object\")\n",
        "      output.append(param)\n",
        "    \n",
        "    for i in range(len(output)):\n",
        "        # Copy Weights and Biases\n",
        "      model = Model()\n",
        "      for idx, wei in enumerate(model.parameters()):\n",
        "          wei.data = (torch.tensor(param[idx])).to(torch.float32)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    y_pred = model(train_x)\n",
        "    y_pred = torch.where(y_pred>=0.5, 1, 0).flatten()\n",
        "    acc = (y_pred == train_y).sum().float().item() / len(train_x)\n",
        "    accuracy = 1 - acc # Optimization function aims to reduce the cost so (1 - accuracy) \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "lmStuH-ScjOT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the particles\n",
        "n_particles = 500\n",
        "dimensions = len(param)\n",
        "x_max = 1.0 * np.ones(dimensions)\n",
        "x_min = -1.0 * x_max\n",
        "bounds = (x_max,x_min)\n",
        "particles = np.random.uniform(low=x_min, high=x_max, size=(n_particles, dimensions))\n",
        "best_fitness = np.inf\n",
        "best_particle = None\n",
        "\n",
        "# Initialize the velocities\n",
        "v_max = 0.1 * (x_max - x_min)\n",
        "v_min = -v_max\n",
        "velocities = np.random.uniform(low=v_min, high=v_max, size=(n_particles, dimensions))\n",
        "\n",
        "# Set the PSO parameters\n",
        "c1 = 0.6\n",
        "c2 = 0.3\n",
        "w = 0.1\n",
        "\n",
        "# Run the PSO algorithm\n",
        "max_iter = 100\n",
        "for i in range(max_iter):\n",
        "    # Evaluate the fitness of the particles\n",
        "    fitness = np.array([objective_function(particles[j], model, train_x, train_y) for j in range(n_particles)])\n",
        "\n",
        "    # Update the global best\n",
        "    if np.min(fitness) < best_fitness:\n",
        "        best_fitness = np.min(fitness)\n",
        "        best_particle = particles[np.argmin(fitness)]\n",
        "\n",
        "    # Update the velocities and positions of the particles\n",
        "    r1 = np.random.uniform(size=(n_particles, dimensions))\n",
        "    r2 = np.random.uniform(size=(n_particles, dimensions))\n",
        "    vel = w * velocities + c1 * r1 * (particles - particles) + c2 * r2 * (best_particle - particles)\n",
        "    particles += vel\n",
        "\n",
        "    # Clip the positions to the bounds\n",
        "    particles = np.clip(particles, x_min, x_max)\n",
        "\n",
        "# Extract best_cost and best_parameter\n",
        "best_cost = best_fitness\n",
        "best_parameter = best_particle\n",
        "\n",
        "# Evaluate the performance of the best parameter\n",
        "best_accuracy = 1 - objective_function(best_parameter, model, train_x, train_y)\n",
        "print(f\"Best Cost : {best_cost}\\n Best Parameter : {best_parameter}\")\n",
        "print(f\"Best Parameter : {best_accuracy}\")"
      ],
      "metadata": {
        "id": "jpKQrlijctkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4636781e"
      },
      "source": [
        "## Testing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8db78c1"
      },
      "outputs": [],
      "source": [
        "test_x = torch.from_numpy(x_test).to(torch.float32)\n",
        "test_y = torch.from_numpy(y_test).to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6fcfda7"
      },
      "outputs": [],
      "source": [
        "test = TensorDataset(test_x,test_y)\n",
        "test = DataLoader(test,batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b4fa006"
      },
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = Model()"
      ],
      "metadata": {
        "id": "5EtvQZj7kJ9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b97279cb"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model(test_x)\n",
        "y_pred = torch.where(y_pred>=0.5, 1, 0).flatten()\n",
        "print(classification_report(y_pred,test_y))"
      ]
    }
  ]
}
